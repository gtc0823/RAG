from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time
import re
import json
import pandas as pd

# è¨­å®šç„¡é ­æ¨¡å¼
chrome_options = Options()
chrome_options.add_argument("--headless")
chrome_options.add_argument("--disable-gpu")
chrome_options.add_argument("--no-sandbox")

# è¨­ç½® User-Agentï¼Œé€™è£¡ç”¨çš„æ˜¯ Chrome ç€è¦½å™¨çš„ User-Agent å­—ä¸²
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36"
chrome_options.add_argument(f"user-agent={user_agent}")

# åˆå§‹åŒ– driver
driver = webdriver.Chrome(options=chrome_options)

def clean_text(text):
    lines = text.split('\n')
    author = 'N/A'

    for line in lines:
        if line.startswith('ä½œè€…'):
            author = line.replace('ä½œè€…', '').strip()

    # å»é™¤ meta è³‡è¨Šï¼ˆå‰ 4 è¡Œï¼‰å’Œç°½åæª”ï¼ˆ-- ä¹‹å¾Œï¼‰
    content_body = re.split(r'--\n', '\n'.join(lines[4:]))[0]
    return author, content_body.strip()

def get_articles_from_page():
    articles = []
    
    # æ‰¾å‡ºæ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œå’Œé€£çµ
    entries = driver.find_elements(By.CSS_SELECTOR, 'div.r-ent')
    for entry in entries:
        try:
            title_el = entry.find_element(By.CSS_SELECTOR, 'div.title > a')
            title = title_el.text
            link = title_el.get_attribute('href')
            nrec_el = entry.find_element(By.CSS_SELECTOR, 'div.nrec > span')
            nrec_text = nrec_el.text.strip()

            # è™•ç† nrecï¼šå¯èƒ½æ˜¯æ•¸å­—ï¼Œä¹Ÿå¯èƒ½æ˜¯ "çˆ†" æˆ– "X1" ä¹‹é¡
            if nrec_text == 'çˆ†':
                nrec = 100  # è‡ªè¨‚ï¼Œä»£è¡¨çˆ†æ–‡
            elif re.match(r'^X\d+$', nrec_text):
                nrec = -int(nrec_text[1:])  # ä¾‹å¦‚ X1 â†’ -1
            elif nrec_text.isdigit():
                nrec = int(nrec_text)
            else:
                nrec = 0

            # é€²å…¥æ–‡ç« 
            driver.execute_script("window.open(arguments[0]);", link)
            driver.switch_to.window(driver.window_handles[1])
            time.sleep(0.1)

            # å–å¾—æ™‚é–“ã€å…§æ–‡
            try:
                main_content = driver.find_element(By.ID, 'main-content').text
                author, content = clean_text(main_content)

                articles.append({
                    "title": title,
                    "url": link,
                    "author": author,
                    "popularity": nrec,
                    "content": content
                })
            except Exception as e:
                print(f"âŒ ç„¡æ³•è®€å–æ–‡ç« å…§å®¹: {e}")
            
            # é—œé–‰åˆ†é 
            driver.close()
            driver.switch_to.window(driver.window_handles[0])
        except:
            continue
    
    return articles

# ä¸»æµç¨‹ï¼šæŠ“å–ä¸€å®šæ•¸é‡çš„é æ•¸
def crawl_cfantasy(pages):
    base_url = "https://www.ptt.cc/bbs/CFantasy/index.html"
    all_articles = []
    
    driver.get(base_url)
    time.sleep(1)  # ç­‰å¾…é é¢åŠ è¼‰å®Œæˆ

    for i in range(pages):
        print(f"æ­£åœ¨æŠ“å–ç¬¬ {i+1} é ...")
        
        # æŠ“å–è©²é çš„æ–‡ç« 
        articles = get_articles_from_page()
        all_articles.extend(articles)
        
        # é»æ“Šã€Œä¸Šä¸€é ã€
        try:
            prev_page_button = driver.find_element(By.LINK_TEXT, 'â€¹ ä¸Šé ') 
            prev_page_button.click()
            time.sleep(0.1)  # ç­‰å¾…é é¢åŠ è¼‰
        except:
            print("âŒ æ²’æœ‰æ›´å¤šé é¢äº†ï¼Œåœæ­¢çˆ¬å–")
            break
    
    return all_articles

# åŸ·è¡Œçˆ¬èŸ²
result = crawl_cfantasy(pages=2)  # çˆ¬å– 2 é 

'''# å­˜æˆ JSON
with open("CFantasy_articles.json", "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=2)
'''

df = pd.DataFrame(result)

df.to_csv("CFantasy_articles.txt", sep=",", index=False, encoding="utf-8")

with open("CFantasy_articles.txt", "w", encoding="utf-8") as f:
    for article in result:
        f.write("ğŸ“Œ Title: " + article.get("title", "N/A") + "\n")
        f.write("Author: " + article.get("author", "N/A") + "\n")
        f.write("Popularity: " + str(article.get("popularity", "N/A")) + "\n")
        f.write("URL: " + article.get("url", "N/A") + "\n\n")
        f.write("Content:\n" + article.get("content", "").strip() + "\n")
        f.write("\n" + "â€”" * 50 + "\n\n")


driver.quit()
print("âœ… çˆ¬å–å®Œæˆï¼å…±æ”¶é›†æ–‡ç« æ•¸é‡ï¼š", len(result))
